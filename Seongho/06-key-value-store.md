# 6장 - 키-값 저장소 설계

## Key-Value Store

키-값 데이터베이스라고도 불리는 비 관계형 데이터베이스다.

저장 되는 값은 고유 식별자 (key)를 가지고 있어야 하고 성능상 키는 짧을 수록 좋다.

대표적으로 Amazon DynamoDB, Apache Cassandra, Memcached, Redis 등이 있음

> put(key, value) : 키-값 쌍을 저장소에 저장
> get(key) :  인자로 주어진 키에 값을 조회

## 문제 이해 및 설계 범위 확정

다음 특성을 갖는 Key-Value store 를 설계한다고 가정

```text
1. key-value 쌍의 크기는 10KB 이하
2. 큰 데이터를 저장할 수 있어야 함
3. 높은 가용성을 제공해야 함 -> 장애가 발생하면 빠르게 응답해야 함
4. 높은 규모 확장성을 제공해야 함 -> 트래픽 양에 따라 자동적으로 서버 증설/삭제가 이루어져야 함
5. 데이터 일관성 수준은 조정이 가능해야 함
6. 응답 latency 가 짧아야 함
```

## 단일 서버 키-값 저장소

키-값 쌍 전부를 메모리에 해시 테이블로 저장하여 만든다.

메모리에 저장되기 때문에 빠른 속도를 보장하지만 모든 데이터를 메모리 안에 두는 것은 불가능하다.

이 문제를 해결하기 위해 다음과 같은 개선책이 있다.

- 데이터 압축
- 자주 쓰이는 데이터만 메모리에 두고 나머지는 디스크에 저장

하지만 저장소 용량은 무한하지 않기 때문에 많은 데이터를 저장하려면 분산 키-값 저장소를 만들어야 한다.

## 분산 키-값 저장소

분산 시스템을 설계할 때 CAP 정리(Consistency, Availability, Partition Tolerance theorem)를 이해하고 있어야 한다.

- 데이터 일관성 (Consistency)
    - 분산 시스템에 접속하는 모든 클라이언트는 언제나 같은 데이터를 봐야함
- 가용성 (Availability)
    - 일부 노드에 장애가 발생하더라도 항상 응답을 받아야 함
- 파티션 감내 (Partition Tolerance)
    - 네트워크에 파티션이 생기더라도 시스템은 계속 동작해야 함

> 파티션: 두 노드 사이에 통신 장애가 발생했음을 의미

### CAP 정리

Consistency, Availability, Partition Tolerance 라는 세 가지 요구사항을 동시에 만족하는 분산 시스템을 설계하는 것은 불가능하다는 정리

→ 어떤 두 가지를 충족하려면 나머지 하나는 반드시 희생되어야 한다.

키-값 저장소는 세 가지 요구사항 가운데 어느 두 가지를 만족하는지 다음과 같이 분류할 수 있음

- CP 시스템: 일관성과 파티션 감내 지원 → 가용성 희생
    - 데이터 불일치를 피하기 위해 쓰기 연산 중단
- AP 시스템: 가용성과 파티션 감내 지원 → 일관성 희생
    - 데이터 불일치가 있더라도 읽기 연산 허용
- CA 시스템: 일관성과 가용성 지원 → 파티션 감내 지원
    - 분산 시스템은 반드시 파티션 문제를 감내할 수 있도록 설계되어야 하기 때문에 실세계는 CA 시스템은 없다.

### 시스템 컴포넌트

> Amazon DynamoDB, Apache Cassandra, BigTable 사례를 참고

### 데이터 파티션

전체 데이터를 한 대 서버에 넣는 것은 불가능하기 때문에 데이터를 작은 파티션들로 분할하여 여러 대 서버에 저장한다.

파티션 단위로 나눌 때 다음 두가지 문제를 중요하게 따지기 때문에 안정 해시를 사용한다.

- 데이터를 여러 서버에 고르게 분산할 수 있는가
- 노드가 추가되거나 삭제될 때 데이터의 이동을 최소화할 수 있는가

### 데이터 다중화

높은 가용성과 안정성을 확보하기 위해서는 데이터를 N개 서버에 비동기적으로 다중화할 필요가 있다.

가상 노드를 사용할 때 같은 물리 서버를 중복 선택하지 않도록 하여 선택한 N 개의 노드가 대응될 실제 물리 서버의 개수가 N 보다 작아지는 문제를 피한다.

### 데이터 일관성

여러 노드에 다중화된 데이터는 적절히 동기화가 되어야 한다.

정족수 합의 (Quorum Consensus) 프로토콜을 사용하여 쓰기/읽기 연산 모두 일관성을 보장한다.

- N = 사본 개수
- W = 쓰기 연산에 대한 정족수 → W 개의 서버로부터 중재자가 쓰기 연산 응답을 받아야 성공해야 쓰기 연산을 성공한 것으로 간주
- R = 읽기 연산에 대한 정속수 → R 개의 서버로부터 중재자가 읽기 연산 응답을 받아야 읽기 연산을 성공한 것으로 간주
- 중재자는 proxy 역할

![a](https://github.com/seongho-joo/Algorithm/assets/45463495/52cec397-6558-401a-8c0f-f806460c2a26)

W, R, N의 값을 정하는 것은 latency 와 consistency 사이의 타협점을 찾는 과정이다.

- W = 1 or R = 1 인 구성의 경우
    - 중재자가 한 대의 응답만 받으면 되기 때문에 latency 가 낮음
- W > 1 or R > 1 인 구성의 경우
    - 중재자가 n 대의 응답을 받기 때문에 strong consistency 를 보장
    - 하지만 latency 가 높아짐

W, R, N의 몇 가지 구성

- R = 1, W = N : 빠른 읽기 연산에 최적화된 시스템
- W = 1, R = N : 빠른 쓰기 연산에 최적화된 시스템
- W + R ≥ N : Strong Consistency 보장 ( N = 3, W = R = 2)
- W + R ≤ N : Strong Consistency 보장하지 않음

**일관성 모델**   
키-값 저장소를 설계할 때 고려해야할 중요한 요소, 일관성 모델은 데이터 일관성의 수준을 결정한다.

- Strong Consistency
    - 모든 읽기 연산은 가장 최근에 갱신된 결과 반환
    - 쓰기 연산이 동기로 처리되어야 함 → 동기화가 완료될 때까지의 latency 가 발생
- Weak Consistency
    - 읽기 연산은 가장 최근에 갱신된 결과를 반환하지 못할 수 있음
- Eventual Consistency
    - Weak Consistency 의 형태
    - 쓰기 연산이 비동기로 처리됨 → 결국엔 모든 사본에 동기화 됨
    - 주로 사용

**비 일관성 해소 기법** : 데이터 버저닝    
데이터를 다중화하면 가용성을 높아지지만 사본 간 일관성이 깨질 가능성이 높아진다.

이 문제를 버저닝(versioning)과 벡터 시계(vector clock)로 해소한다.

- versioning
    - 데이터를 변경할 때마다 해당 데이터의 새로운 버전 생성
    - 각 버전의 데이터는 immutable
- vector clock
    - [서버, 버전]의 순서쌍을 데이터에 매단 것
    - D([S1, v1], [S2, v2], …, [Sn, vn])와 같이 표현
        - [Si, vi]가 있으면 vi 증가
        - 없을 경우 새 항목 [Si, 1] 생성
    - 벡터 시계의 단점
        - 충돌 감지 및 해소 로직이 클라이언트에 들어감 → 클라이언트 구현이 복잡해짐
        - 순서쌍 개수가 굉장히 빨리 늘어남
            - 어떤 임계치를 설정하고, 임계치 이상으로 길이가 길어지면 오래된 순서쌍을 벡터 시계에서 제거함
                - 버전 간 선후 관계가 정확하게 결정될 수 없기 때문에 충돌 해소 과정의 효율성이 낮아짐 → DynamoDB에 따르면 아마존은 실제 서비스에서 그런 문제 발견 X

### 장애 처리

대다수 대규모 시스템에서 장애는 아주 한하게 벌어진다. 따라서 장애를 어떻게 처리할 것이냐 하는 것은 굉장히 중요한 문제다.

- 장애 감지
    - 모든 노드 사이에 멀티 캐스팅 채널 구축 → 서버가 많을 때 비효율적임
    - 가십 프로토콜(gossip protocol) 같은 분산형 장애 가지 솔루션 채택
        - 각 노드는 멤버십 목록 유지
        - 각 노드는 주기적으로 자신의 박동 카운터를 증가시킴
        - 박동 카운터 목록을 받은 노드는 멤버십 목록을 최신 값으로 갱신
        - 어떤 멤버의 박동 카운터 값이 지정된 시간 동안 갱신되지 않으면 해당 멤버는 장애 상태인 것으로 간주
- 일시 장애 처리
    - 엄격한 정족수 접근법 → 읽기 쓰기 연산 금지
    - 느슨한 정족수 접근법
        - 장애 상태인 서버는 무시하여 W개의 서버, R 개의 서버를 해시링에서 골라 요청을 임시적으로 처리
        - 서버가 복구된다면 일관성을 유지하기 위해 일관 반영
- 영구 장애 처리
    - 반 엔트로피 프로토콜을 구현하여 사본들을 동기화
    - 반 엔트로피 프로콜은 사본들을 비교하여 최신 버전으로 갱신하는 과정을 포함
    - 사본 간의 일관성이 망가진 상태를 탐지하고 전송 데이터의 양을 줄이기 위해 [머클 트리](https://www.lesstif.com/security/merkle-tree-125305097.html)(Merkle Tree) 사용
- 데이터 센터 장애 처리
    - 데이터 센터 다중화

### 시스템 아키텍처 다이어그램

- 클라이언트는 키-값 저장소가 제공하는 두 가지 API와 통신
- 중재자는 클라이언트에게 키-값 저장소에 대한 proxy 역할을 하는 노드
- 노드는 안정 해시의 해시 링위에 분포
- 노드를 자동으로 추가 또는 삭제할 수 있도록, 시스템은 완전히 분산
- 데이터는 여러 노드에 다중화됨
- 모든 노드가 같은 책임을 지므로, SPOF(Single Point of Failure) 는 존재하지 않음

### 쓰기 경로와 읽기 경로

카산드라 사례를 참고함

- 쓰기 경로

![Untitled](https://github.com/seongho-joo/Algorithm/assets/45463495/7b70646e-7492-4453-a3ff-10efbcb6719b)

1. 쓰기 요청이 커밋 로그에 기록됨
2. 데이터가 메모리 캐시에 기록
3. 메모리 캐시가 가득차거나 임계치에 도달하면 데이터는 디스크에 있는 [SSTable](https://velog.io/@yunhongmin/SSTable-data-storage) 에 기록됨

- 읽기 경로

![Untitled](https://github.com/seongho-joo/Algorithm/assets/45463495/2902cab3-fc97-46e4-ab45-45258367654f)

1. 데이터가 메모리 있는지 검사
2. 데이터가 메모리에 없으므로 블룸 필터를 검사
3. 블룸 필터를 통해 어떤 SSTable 에 키가 보관되어 있는지 찾음
4. SStable 에서 데이터를 가져옴
5. 해당 데이터를 클라이언트에게 반환

## 요약

| 목표/문제               | 기술                                                       |
|---------------------|----------------------------------------------------------|
| 대규모 데이터 저장          | 안정 해시를 사용해 서버에 부하 분산                                     |
| 읽기 연산에 대한 높은 가용성 보장 | 데이터를 여러 데이터센터에 다중화                                       |
| 쓰기 연산에 대한 높은 가용성 보장 | 버저닝 및 벡터 시계를 사용한 충돌 해소                                   |
| 데이터 파티션             | Consistent Hash                                          |
| 다양성(heterogeneity)  | Consistent Hash                                          |
| 조절 가능한 데이터 일관성      | 정족수 합의(quorum consensus)                                 |
| 일시적 장애 처리           | 느슨한 정족수 프로토콜(sloppy quorum) 과 단서 후 임시 위탁(hinted handoff) |
| 영구적 장애 처리           | 머클 트리(Merkle tree)                                       |
| 데이터 센터 장애 대응        | 여러 데이터 센터에 걸친 데이터 다중화                                    |